{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moriahsantiago/UPenn-Data-Science-Digital-Learning/blob/main/Week_14_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Networks and Deep Learning\n",
        "In this assignment, you will be training and evaluating neural networks and other models for the task of developing automated sensor-free detectors of student affect (i.e. concentration, boredom, confusion, and frustration)."
      ],
      "metadata": {
        "id": "tTmSUN8xbZVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "This assignment will utilize student data collected from the ASSISTments digital learning platform. The dataset contains 48,716 rows of data from 838 unique students. Each row represents one \"clip\" of student activity; a clip is meant to represent approximately 20 seconds of actions, but may vary. Each clip is described by 92 features; these expert-engineered features are the result of taking the average, sum, minimum, and maximum value of 23 action-level features when aggregating to the clip-level (i.e. 23 features x 4 aggregations = 92). The dataset also contains 3,109 observations of affect collected by human coders using the [BROMP protocol](https://d1wqtxts1xzle7.cloudfront.net/36773439/BROMP_2.0_Final-libre.pdf?1424899724=&response-content-disposition=inline%3B+filename%3DBaker_Rodrigo_Ocumpaugh_Monitoring_Proto.pdf&Expires=1708897741&Signature=MkENDA~A6ZDfWOD--VrdUT73ngf4~bQJ48Nq1DOnyZkq~h8zwcSben4URR8MnGipxbgbzxkpRE4pfIaLSBRBq5G62-C3DYdw60Kjx0qTsBCQoIWu6XmqPz6ACzyslcJwc~LA7vDIiJ3MVs1CGVccZnDFaFP6YzAnkAbK3HuZ1UgkT3OsxorsD7p7pbgF0P0WEb6X9NevtNAxNbEbzSN7r0mrjAoESZdFkat~q1eVyAcPhQ-ONGB-aK-FzDImMlC7gjxRqiq2J7Husp5RVFVuQ3v7v-gfvyq7rC8Clabci1EkaaCjbF9qxLiibwl5End3Tre6MQkgV4tu7tY~kSOciQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA); students were labeled as exhibiting either concentration, boredom, confusion, or frustration. These labels were collected in a round-robin fashion, such that not every row in the dataset contains a label, resulting in a large number of unlabeled data rows.\n",
        "\n",
        "**The dataset can be downloaded from this direct link:\n",
        "[ASSISTments Affect Labels and Features](https://drive.google.com/file/d/19v4vzxsvHM_zm2a_9Zvquhf_Z4HGtu2a/view?usp=sharing)**\n",
        "\n",
        "Versions of this dataset have been used in prior works:\n",
        "\n",
        "* [Ocumpaugh, J., Baker, R., Gowda, S., Heffernan, N., & Heffernan, C. (2014). Population validity for educational data mining models: A case study in affect detection. *British Journal of Educational Technology*, 45(3), 487-501.](https://bera-journals.onlinelibrary.wiley.com/doi/full/10.1111/bjet.12156)\n",
        "\n",
        "* [Botelho, A. F., Baker, R. S., & Heffernan, N. T. (2017, June). Improving Sensor-Free Affect Detection Using Deep Learning. *In Proceedings of the 2017 International Conference on Artificial Intelligence in Education*, 40-51. Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-319-61425-0_4)"
      ],
      "metadata": {
        "id": "2LCsq4SUVc2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loading and Preprocessing\n",
        "Download the **student_affect_with_clip_features_and_folds.csv** file from the link above. Run the first code cell below to upload the dataset. The second code cell below uses the pandas library to read the file into a Dataframe and displays the number of rows and columns as well as a sample of the loaded data.\n",
        "\n",
        "*Note: The dataset has already been folded at the student-level. We will be using the \"fold\" column of this dataset to apply cross-validation*\n",
        "\n"
      ],
      "metadata": {
        "id": "tv3v15DIceLI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "25P0zowFbY7w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "763f2ee7-7a77-4ad3-d3a8-ede941bb794e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c94ed602-8f25-4469-bb96-c93503268179\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c94ed602-8f25-4469-bb96-c93503268179\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving student_affect_with_clip_features_and_folds.csv to student_affect_with_clip_features_and_folds.csv\n",
            "student_affect_with_clip_features_and_folds.csv has been uploaded\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "dataset = files.upload()\n",
        "filename = list(dataset.keys())[0]\n",
        "print(f\"{filename} has been uploaded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pk\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the prefixes\n",
        "prefixes = [\"avg_\", \"sum_\", \"min_\", \"max_\"]\n",
        "\n",
        "TARGET_FEATURES = ['confusion', 'concentration', 'frustration', 'boredom']\n",
        "\n",
        "data = pd.read_csv(filename)\n",
        "EXPERT_FEATURES = [col for col in data.columns if any(col.lower().startswith(prefix.lower()) for prefix in prefixes)]\n",
        "data[TARGET_FEATURES] = data[TARGET_FEATURES].fillna(0)\n",
        "\n",
        "# Print the shape of the dataset\n",
        "print(\"\\nShape of the dataset (rows, columns):\", data.shape)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "hRUuy6fK3rJj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "5448c509-9193-472c-b609-1b3e1764a1a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of the dataset (rows, columns): (48716, 106)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       row_id  clip_id  skill   problem_id  user_id  assignment_id  \\\n",
              "0           0        1    281    136.00000    72720       287761.0   \n",
              "1           1        2    281    136.00000    72720       287761.0   \n",
              "2           2        3     24   4468.00000    72720       287767.0   \n",
              "3           3        5     24   4464.00000    72720       287767.0   \n",
              "4           4        7     42   4465.00000    72720       287767.0   \n",
              "...       ...      ...    ...          ...      ...            ...   \n",
              "48711   48720    92477     78  86278.50000   155781       529087.0   \n",
              "48712   48721    92479     79  87298.50000   155781       529088.0   \n",
              "48713   48722    92481     47  84974.00000   155781       529090.0   \n",
              "48714   48723    92482     47  84952.00000   155781       529090.0   \n",
              "48715   48724    92484     47  84873.33333   155781       529090.0   \n",
              "\n",
              "       assistment_id  avg_attemptCount  avg_bottomHint  avg_correct  ...  \\\n",
              "0              136.0               1.0             0.0     0.000000  ...   \n",
              "1              136.0               2.0             0.0     0.000000  ...   \n",
              "2             4468.0               1.5             0.0     0.000000  ...   \n",
              "3             4468.0               1.5             0.0     0.500000  ...   \n",
              "4             4468.0               3.5             0.0     0.166667  ...   \n",
              "...              ...               ...             ...          ...  ...   \n",
              "48711        47799.0               1.0             0.0     1.000000  ...   \n",
              "48712        48669.5               1.0             0.0     1.000000  ...   \n",
              "48713        46686.0               1.0             0.0     1.000000  ...   \n",
              "48714        46664.0               1.5             0.0     0.500000  ...   \n",
              "48715        46612.0               1.0             0.0     1.000000  ...   \n",
              "\n",
              "       sum_totalFrPercentPastWrong  sum_totalFrSkillOpportunities  \\\n",
              "0                         0.000000                              0   \n",
              "1                         0.000000                              1   \n",
              "2                         0.000000                              1   \n",
              "3                         0.500000                              5   \n",
              "4                         0.000000                             15   \n",
              "...                            ...                            ...   \n",
              "48711                     0.500000                             14   \n",
              "48712                     0.904167                             31   \n",
              "48713                     0.111111                              9   \n",
              "48714                     0.100000                             21   \n",
              "48715                     0.231685                             39   \n",
              "\n",
              "       sum_totalFrTimeOnSkill  confusion  concentration  boredom  frustration  \\\n",
              "0                     0.00000        0.0            0.0      0.0          0.0   \n",
              "1                   186.65000        0.0            0.0      0.0          0.0   \n",
              "2                    54.56500        0.0            0.0      0.0          0.0   \n",
              "3                   133.86500        0.0            0.0      0.0          0.0   \n",
              "4                   836.40199        0.0            0.0      0.0          0.0   \n",
              "...                       ...        ...            ...      ...          ...   \n",
              "48711               213.01198        0.0            0.0      0.0          0.0   \n",
              "48712               458.56597        0.0            0.0      0.0          0.0   \n",
              "48713               343.83000        0.0            0.0      0.0          0.0   \n",
              "48714               732.08400        0.0            0.0      0.0          0.0   \n",
              "48715              1155.22294        0.0            0.0      0.0          0.0   \n",
              "\n",
              "       urbanicity  clip_sequence  fold  \n",
              "0               1              1     1  \n",
              "1               1              1     1  \n",
              "2               1              1     1  \n",
              "3               1              1     1  \n",
              "4               1              1     1  \n",
              "...           ...            ...   ...  \n",
              "48711           3            838     4  \n",
              "48712           3            838     4  \n",
              "48713           3            838     4  \n",
              "48714           3            838     4  \n",
              "48715           3            838     4  \n",
              "\n",
              "[48716 rows x 106 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e098dece-c22f-4db8-8d45-004122a6d117\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>clip_id</th>\n",
              "      <th>skill</th>\n",
              "      <th>problem_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>assignment_id</th>\n",
              "      <th>assistment_id</th>\n",
              "      <th>avg_attemptCount</th>\n",
              "      <th>avg_bottomHint</th>\n",
              "      <th>avg_correct</th>\n",
              "      <th>...</th>\n",
              "      <th>sum_totalFrPercentPastWrong</th>\n",
              "      <th>sum_totalFrSkillOpportunities</th>\n",
              "      <th>sum_totalFrTimeOnSkill</th>\n",
              "      <th>confusion</th>\n",
              "      <th>concentration</th>\n",
              "      <th>boredom</th>\n",
              "      <th>frustration</th>\n",
              "      <th>urbanicity</th>\n",
              "      <th>clip_sequence</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>281</td>\n",
              "      <td>136.00000</td>\n",
              "      <td>72720</td>\n",
              "      <td>287761.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>281</td>\n",
              "      <td>136.00000</td>\n",
              "      <td>72720</td>\n",
              "      <td>287761.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>186.65000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>4468.00000</td>\n",
              "      <td>72720</td>\n",
              "      <td>287767.0</td>\n",
              "      <td>4468.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>54.56500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>4464.00000</td>\n",
              "      <td>72720</td>\n",
              "      <td>287767.0</td>\n",
              "      <td>4468.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>133.86500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>42</td>\n",
              "      <td>4465.00000</td>\n",
              "      <td>72720</td>\n",
              "      <td>287767.0</td>\n",
              "      <td>4468.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "      <td>836.40199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48711</th>\n",
              "      <td>48720</td>\n",
              "      <td>92477</td>\n",
              "      <td>78</td>\n",
              "      <td>86278.50000</td>\n",
              "      <td>155781</td>\n",
              "      <td>529087.0</td>\n",
              "      <td>47799.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>14</td>\n",
              "      <td>213.01198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>838</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48712</th>\n",
              "      <td>48721</td>\n",
              "      <td>92479</td>\n",
              "      <td>79</td>\n",
              "      <td>87298.50000</td>\n",
              "      <td>155781</td>\n",
              "      <td>529088.0</td>\n",
              "      <td>48669.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.904167</td>\n",
              "      <td>31</td>\n",
              "      <td>458.56597</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>838</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48713</th>\n",
              "      <td>48722</td>\n",
              "      <td>92481</td>\n",
              "      <td>47</td>\n",
              "      <td>84974.00000</td>\n",
              "      <td>155781</td>\n",
              "      <td>529090.0</td>\n",
              "      <td>46686.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>9</td>\n",
              "      <td>343.83000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>838</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48714</th>\n",
              "      <td>48723</td>\n",
              "      <td>92482</td>\n",
              "      <td>47</td>\n",
              "      <td>84952.00000</td>\n",
              "      <td>155781</td>\n",
              "      <td>529090.0</td>\n",
              "      <td>46664.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>21</td>\n",
              "      <td>732.08400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>838</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48715</th>\n",
              "      <td>48724</td>\n",
              "      <td>92484</td>\n",
              "      <td>47</td>\n",
              "      <td>84873.33333</td>\n",
              "      <td>155781</td>\n",
              "      <td>529090.0</td>\n",
              "      <td>46612.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.231685</td>\n",
              "      <td>39</td>\n",
              "      <td>1155.22294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>838</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48716 rows × 106 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e098dece-c22f-4db8-8d45-004122a6d117')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e098dece-c22f-4db8-8d45-004122a6d117 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e098dece-c22f-4db8-8d45-004122a6d117');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c7174c6c-30d0-4a79-9b77-d65a1a83a84f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7174c6c-30d0-4a79-9b77-d65a1a83a84f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c7174c6c-30d0-4a79-9b77-d65a1a83a84f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_157674ca-7174-46ff-a6dd-001c80d61988\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_157674ca-7174-46ff-a6dd-001c80d61988 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if we have the right features\n",
        "print(\"Number of columns:\", len(data.columns))\n",
        "print(\"Target features present:\", [col for col in TARGET_FEATURES if col in data.columns])\n",
        "print(\"Sample of behavioral features:\", [col for col in data.columns if any(col.startswith(prefix) for prefix in prefixes)][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTsQ0TT4eQGu",
        "outputId": "8412a0a9-c3d4-4da5-8a64-defd225eabde"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns: 106\n",
            "Target features present: ['confusion', 'concentration', 'frustration', 'boredom']\n",
            "Sample of behavioral features: ['avg_attemptCount', 'avg_bottomHint', 'avg_correct', 'avg_frIsHelpRequest', 'avg_frPast5HelpRequest']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Properly filter to only behavioral features and targets\n",
        "EXPERT_FEATURES = [col for col in data.columns if any(col.lower().startswith(prefix.lower()) for prefix in prefixes)]\n",
        "data_filtered = data[EXPERT_FEATURES + TARGET_FEATURES]\n",
        "\n",
        "# Print the new shape\n",
        "print(\"Filtered dataset shape:\", data_filtered.shape)\n",
        "print(\"Features kept:\", len(EXPERT_FEATURES), \"behavioral features +\", len(TARGET_FEATURES), \"target features\")\n",
        "\n",
        "# Update our main dataframe\n",
        "data = data_filtered\n",
        "print(\"Final dataset shape:\", data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-scd6Ja4eZlC",
        "outputId": "41f6cd01-2efa-4fa0-f25f-5125da2575ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset shape: (48716, 96)\n",
            "Features kept: 92 behavioral features + 4 target features\n",
            "Final dataset shape: (48716, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Utility Functions\n",
        "The code cell below provides an implementation of AUC for multi-class prediction (following the method suggested by Hand & Till, 2001) as well as for traditional binary prediction tasks.\n",
        "\n",
        "[Hand, D. J., & Till, R. J. (2001). A simple generalisation of the area under the ROC curve for multiple class classification problems. *Machine learning, 45, 171-186.](https://link.springer.com/article/10.1023/A:1010920819831)"
      ],
      "metadata": {
        "id": "ChH5ZGgyFDsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alen(x):\n",
        "    return 1 if np.isscalar(x) else len(x)\n",
        "\n",
        "def auc(actual, predicted, average_over_labels=True, partition=1024.):\n",
        "    assert len(actual) == len(predicted)\n",
        "\n",
        "    ac = np.array(actual, dtype=np.float32).reshape((len(actual),-1))\n",
        "    pr = np.array(predicted, dtype=np.float32).reshape((len(predicted),-1))\n",
        "\n",
        "    na = np.argwhere([not np.any(np.isnan(i)) for i in ac]).ravel()\n",
        "\n",
        "    ac = ac[na]\n",
        "    pr = pr[na]\n",
        "\n",
        "    label_auc = []\n",
        "    for i in range(ac.shape[-1]):\n",
        "        a = np.array(ac[:,i])\n",
        "        p = np.array(pr[:,i])\n",
        "\n",
        "        val = np.unique(a)\n",
        "        if len(val) == 1:\n",
        "            label_auc.append(np.nan)\n",
        "            continue\n",
        "\n",
        "        pos = np.argwhere(a[:] >= np.median(val))\n",
        "        neg = np.argwhere(a[:] < np.median(val))\n",
        "\n",
        "        p_div = int(np.ceil(len(pos)/partition))\n",
        "        n_div = int(np.ceil(len(neg)/partition))\n",
        "\n",
        "        div = 0\n",
        "        for j in range(int(p_div)):\n",
        "            p_range = list(range(int(j * partition), int(np.minimum(int((j + 1) * partition), len(pos)))))\n",
        "            for k in range(n_div):\n",
        "                n_range = list(range(int(k * partition), int(np.minimum(int((k + 1) * partition), len(neg)))))\n",
        "\n",
        "\n",
        "                eq = np.ones((alen(neg[n_range]), alen(pos[p_range]))) * p[pos[p_range]].T == np.ones(\n",
        "                    (alen(neg[n_range]), alen(pos[p_range]))) * p[neg[n_range]]\n",
        "\n",
        "                geq = np.array(np.ones((alen(neg[n_range]), alen(pos[p_range]))) *\n",
        "                               p[pos[p_range]].T >= np.ones((alen(neg[n_range]),\n",
        "                                                             alen(pos[p_range]))) * p[neg[n_range]],\n",
        "                               dtype=np.float32)\n",
        "                geq[eq[:, :] == True] = 0.5\n",
        "                div += np.sum(geq)\n",
        "\n",
        "        label_auc.append(div / (alen(pos)*alen(neg)))\n",
        "\n",
        "    if average_over_labels:\n",
        "        return np.nanmean(label_auc)\n",
        "    else:\n",
        "        return label_auc"
      ],
      "metadata": {
        "id": "S1RHJ33kFlVO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Feed Forward Neural Network\n",
        "\n",
        "The code cell below formats the data for a non-recurrent model (such as a Feed Forward Neural Network or any of the prediction models that have previously been introduced).\n",
        "\n",
        "The second code cell applies a 5-fold cross-validation on a Feed Forward Neural Network.\n",
        "\n",
        "**Please follow the instructions in the ASSISTments assignment for modifying and running the cross-validation code cell.**"
      ],
      "metadata": {
        "id": "eNKFXur6Hzvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use corrected data from the diagnostic step\n",
        "keepers = original_data[TARGET_FEATURES].sum(axis=1) == 1\n",
        "X_nonrecurrent = np.array(original_data[EXPERT_FEATURES][keepers])\n",
        "y_nonrecurrent = np.array(original_data[TARGET_FEATURES][keepers])\n",
        "fold_nonrecurrent = np.array(original_data['fold'][keepers])\n",
        "\n",
        "print(\"X_nonrecurrent.shape:\", X_nonrecurrent.shape)\n",
        "print(\"y_nonrecurrent.shape:\", y_nonrecurrent.shape)"
      ],
      "metadata": {
        "id": "gu7LUYUY_NTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e4fa0c-2065-4a74-fc37-86cbf358faee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_nonrecurrent.shape: (3109, 92)\n",
            "y_nonrecurrent.shape: (3109, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what columns we currently have\n",
        "print(\"Current columns in data:\", list(data.columns))\n",
        "print(\"Length of current data:\", len(data))\n",
        "\n",
        "# Make sure we have the fold column\n",
        "# Re-read the original data to get the fold column back\n",
        "import pandas as pd\n",
        "\n",
        "# Read the original CSV file again to get all columns including 'fold'\n",
        "original_data = pd.read_csv(filename)\n",
        "print(\"Original data shape:\", original_data.shape)\n",
        "print(\"Original columns include 'fold':\", 'fold' in original_data.columns)\n",
        "\n",
        "# Now let's properly filter while keeping the fold column\n",
        "keepers = original_data[TARGET_FEATURES].sum(axis=1) == 1\n",
        "X_nonrecurrent = np.array(original_data[EXPERT_FEATURES][keepers])\n",
        "y_nonrecurrent = np.array(original_data[TARGET_FEATURES][keepers])\n",
        "fold_nonrecurrent = np.array(original_data['fold'][keepers])\n",
        "\n",
        "print(\"Filtered data shapes:\")\n",
        "print(\"X_nonrecurrent.shape:\", X_nonrecurrent.shape)\n",
        "print(\"y_nonrecurrent.shape:\", y_nonrecurrent.shape)\n",
        "print(\"fold_nonrecurrent.shape:\", fold_nonrecurrent.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD__tl2xgI3D",
        "outputId": "cb4c119c-bf26-45c4-c47a-0bed442254a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current columns in data: ['avg_attemptCount', 'avg_bottomHint', 'avg_correct', 'avg_frIsHelpRequest', 'avg_frPast5HelpRequest', 'avg_frPast5WrongCount', 'avg_frPast8HelpRequest', 'avg_frPast8WrongCount', 'avg_frWorkingInSchool', 'avg_hint', 'avg_hintCount', 'avg_hintTotal', 'avg_original', 'avg_past8BottomOut', 'avg_scaffold', 'avg_stlHintUsed', 'avg_timeSinceSkill', 'avg_timeTaken', 'avg_totalFrAttempted', 'avg_totalFrPastWrongCount', 'avg_totalFrPercentPastWrong', 'avg_totalFrSkillOpportunities', 'avg_totalFrTimeOnSkill', 'max_attemptCount', 'max_bottomHint', 'max_correct', 'max_frIsHelpRequest', 'max_frPast5HelpRequest', 'max_frPast5WrongCount', 'max_frPast8HelpRequest', 'max_frPast8WrongCount', 'max_frWorkingInSchool', 'max_hint', 'max_hintCount', 'max_hintTotal', 'max_original', 'max_past8BottomOut', 'max_scaffold', 'max_stlHintUsed', 'max_timeSinceSkill', 'max_timeTaken', 'max_totalFrAttempted', 'max_totalFrPastWrongCount', 'max_totalFrPercentPastWrong', 'max_totalFrSkillOpportunities', 'max_totalFrTimeOnSkill', 'min_attemptCount', 'min_bottomHint', 'min_correct', 'min_frIsHelpRequest', 'min_frPast5HelpRequest', 'min_frPast5WrongCount', 'min_frPast8HelpRequest', 'min_frPast8WrongCount', 'min_frWorkingInSchool', 'min_hint', 'min_hintCount', 'min_hintTotal', 'min_original', 'min_past8BottomOut', 'min_scaffold', 'min_stlHintUsed', 'min_timeSinceSkill', 'min_timeTaken', 'min_totalFrAttempted', 'min_totalFrPastWrongCount', 'min_totalFrPercentPastWrong', 'min_totalFrSkillOpportunities', 'min_totalFrTimeOnSkill', 'sum_attemptCount', 'sum_bottomHint', 'sum_correct', 'sum_frIsHelpRequest', 'sum_frPast5HelpRequest', 'sum_frPast5WrongCount', 'sum_frPast8HelpRequest', 'sum_frPast8WrongCount', 'sum_frWorkingInSchool', 'sum_hint', 'sum_hintCount', 'sum_hintTotal', 'sum_original', 'sum_past8BottomOut', 'sum_scaffold', 'sum_stlHintUsed', 'sum_timeSinceSkill', 'sum_timeTaken', 'sum_totalFrAttempted', 'sum_totalFrPastWrongCount', 'sum_totalFrPercentPastWrong', 'sum_totalFrSkillOpportunities', 'sum_totalFrTimeOnSkill', 'confusion', 'concentration', 'frustration', 'boredom']\n",
            "Length of current data: 48716\n",
            "Original data shape: (48716, 106)\n",
            "Original columns include 'fold': True\n",
            "Filtered data shapes:\n",
            "X_nonrecurrent.shape: (3109, 92)\n",
            "y_nonrecurrent.shape: (3109, 4)\n",
            "fold_nonrecurrent.shape: (3109,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Masking, Dense, LSTM, TimeDistributed, Dropout, Normalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
        "\n",
        "# Set a seed value\n",
        "seed_value= 42\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "auc_scores = []\n",
        "kappa_scores = []\n",
        "\n",
        "for fold in np.unique(fold_nonrecurrent):\n",
        "    training = np.argwhere(fold_nonrecurrent != fold).ravel()\n",
        "    testing = np.argwhere(fold_nonrecurrent == fold).ravel()\n",
        "\n",
        "    X_train, X_test = X_nonrecurrent[training], X_nonrecurrent[testing]\n",
        "    y_train, y_test = y_nonrecurrent[training], y_nonrecurrent[testing]\n",
        "\n",
        "    # Define the model\n",
        "    keras.backend.clear_session()\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(92,)), # this represents the input layer and first hidden layer\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model with the new training and validation sets\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=100,\n",
        "                        validation_split=0.2,\n",
        "                        verbose=1, # setting this to 0 reduces the amount printed\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "     # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # AUC\n",
        "    auc_score = auc(y_test, y_pred)\n",
        "\n",
        "    # Kappa Score\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    kappa_score = cohen_kappa_score(y_true_classes, y_pred_classes)\n",
        "\n",
        "    auc_scores.append(auc_score)\n",
        "    kappa_scores.append(kappa_score)\n",
        "\n",
        "# Calculate the average AUC and Kappa scores across all folds\n",
        "average_auc = np.mean(auc_scores)\n",
        "average_kappa = np.mean(kappa_scores)\n",
        "\n",
        "print(f\"Average AUC: {average_auc}\")\n",
        "print(f\"Average Kappa: {average_kappa}\")\n"
      ],
      "metadata": {
        "id": "Oj8wmtFABfQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b44f3e5-d499-4f9f-94ad-10c7fbaa8aca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6948 - loss: 21.6678 - val_accuracy: 0.7480 - val_loss: 4.6558\n",
            "Epoch 2/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7351 - loss: 3.3082 - val_accuracy: 0.7077 - val_loss: 3.1212\n",
            "Epoch 3/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7470 - loss: 2.5523 - val_accuracy: 0.7782 - val_loss: 5.2833\n",
            "Epoch 4/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 2.9749 - val_accuracy: 0.7097 - val_loss: 4.7769\n",
            "Epoch 5/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 2.9634 - val_accuracy: 0.7177 - val_loss: 4.8484\n",
            "Epoch 6/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7675 - loss: 2.5293 - val_accuracy: 0.7379 - val_loss: 2.6644\n",
            "Epoch 7/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7692 - loss: 1.5086 - val_accuracy: 0.7823 - val_loss: 2.7646\n",
            "Epoch 8/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7527 - loss: 2.0817 - val_accuracy: 0.7601 - val_loss: 2.2596\n",
            "Epoch 9/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7773 - loss: 1.5433 - val_accuracy: 0.7238 - val_loss: 2.3769\n",
            "Epoch 10/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7836 - loss: 1.4622 - val_accuracy: 0.7077 - val_loss: 3.9195\n",
            "Epoch 11/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7875 - loss: 2.0407 - val_accuracy: 0.6270 - val_loss: 3.5477\n",
            "Epoch 12/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7706 - loss: 1.9018 - val_accuracy: 0.7802 - val_loss: 2.4501\n",
            "Epoch 13/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7775 - loss: 1.4204 - val_accuracy: 0.7480 - val_loss: 2.3956\n",
            "Epoch 14/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 1.3909 - val_accuracy: 0.7399 - val_loss: 2.5608\n",
            "Epoch 15/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7897 - loss: 1.6243 - val_accuracy: 0.7298 - val_loss: 1.7625\n",
            "Epoch 16/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 1.3824 - val_accuracy: 0.6593 - val_loss: 2.8457\n",
            "Epoch 17/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.9953 - val_accuracy: 0.7601 - val_loss: 1.9207\n",
            "Epoch 18/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7840 - loss: 1.3498 - val_accuracy: 0.7984 - val_loss: 2.7474\n",
            "Epoch 19/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7971 - loss: 1.6619 - val_accuracy: 0.7419 - val_loss: 1.9649\n",
            "Epoch 20/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 1.4102 - val_accuracy: 0.7077 - val_loss: 2.3684\n",
            "Epoch 21/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 1.3028 - val_accuracy: 0.7823 - val_loss: 2.1153\n",
            "Epoch 22/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 1.5570 - val_accuracy: 0.7440 - val_loss: 1.8448\n",
            "Epoch 23/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 1.1563 - val_accuracy: 0.7762 - val_loss: 1.7165\n",
            "Epoch 24/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 1.2332 - val_accuracy: 0.7621 - val_loss: 1.7653\n",
            "Epoch 25/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 1.2011 - val_accuracy: 0.6835 - val_loss: 1.9190\n",
            "Epoch 26/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8185 - loss: 0.9417 - val_accuracy: 0.7238 - val_loss: 3.0564\n",
            "Epoch 27/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 1.2646 - val_accuracy: 0.6371 - val_loss: 2.2906\n",
            "Epoch 28/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8232 - loss: 0.7943 - val_accuracy: 0.7399 - val_loss: 2.0275\n",
            "Epoch 29/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 1.1135 - val_accuracy: 0.7016 - val_loss: 1.9137\n",
            "Epoch 30/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8182 - loss: 0.7955 - val_accuracy: 0.7560 - val_loss: 1.9202\n",
            "Epoch 31/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 1.0755 - val_accuracy: 0.7944 - val_loss: 1.4402\n",
            "Epoch 32/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.9520 - val_accuracy: 0.7964 - val_loss: 1.3156\n",
            "Epoch 33/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 0.8893 - val_accuracy: 0.7258 - val_loss: 1.6440\n",
            "Epoch 34/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.9003 - val_accuracy: 0.7722 - val_loss: 1.4438\n",
            "Epoch 35/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.7984 - val_accuracy: 0.7460 - val_loss: 1.4520\n",
            "Epoch 36/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8337 - loss: 0.8018 - val_accuracy: 0.7500 - val_loss: 1.4559\n",
            "Epoch 37/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.8241 - val_accuracy: 0.7762 - val_loss: 1.3307\n",
            "Epoch 38/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.9967 - val_accuracy: 0.7117 - val_loss: 2.4287\n",
            "Epoch 39/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8210 - loss: 0.7988 - val_accuracy: 0.7661 - val_loss: 1.5832\n",
            "Epoch 40/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8198 - loss: 0.8284 - val_accuracy: 0.8024 - val_loss: 1.2671\n",
            "Epoch 41/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8224 - loss: 0.7882 - val_accuracy: 0.7198 - val_loss: 1.5983\n",
            "Epoch 42/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8109 - loss: 0.7492 - val_accuracy: 0.7883 - val_loss: 1.6759\n",
            "Epoch 43/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.7687 - val_accuracy: 0.7319 - val_loss: 1.7908\n",
            "Epoch 44/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.8022 - val_accuracy: 0.7883 - val_loss: 1.2868\n",
            "Epoch 45/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.7156 - val_accuracy: 0.7742 - val_loss: 1.3152\n",
            "Epoch 46/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.6891 - val_accuracy: 0.8024 - val_loss: 1.2539\n",
            "Epoch 47/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.7223 - val_accuracy: 0.7823 - val_loss: 1.1983\n",
            "Epoch 48/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.7078 - val_accuracy: 0.7762 - val_loss: 1.4381\n",
            "Epoch 49/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8311 - loss: 0.7355 - val_accuracy: 0.7560 - val_loss: 1.3424\n",
            "Epoch 50/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.6594 - val_accuracy: 0.7399 - val_loss: 1.3698\n",
            "Epoch 51/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.6446 - val_accuracy: 0.7702 - val_loss: 1.2203\n",
            "Epoch 52/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.6395 - val_accuracy: 0.7762 - val_loss: 1.2281\n",
            "Epoch 53/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.6395 - val_accuracy: 0.7964 - val_loss: 1.1922\n",
            "Epoch 54/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8377 - loss: 0.6694 - val_accuracy: 0.7520 - val_loss: 1.3212\n",
            "Epoch 55/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.5028 - val_accuracy: 0.7802 - val_loss: 1.1232\n",
            "Epoch 56/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.5046 - val_accuracy: 0.7702 - val_loss: 1.1698\n",
            "Epoch 57/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.5151 - val_accuracy: 0.7298 - val_loss: 1.3543\n",
            "Epoch 58/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: 0.4983 - val_accuracy: 0.7601 - val_loss: 1.3601\n",
            "Epoch 59/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.5344 - val_accuracy: 0.7843 - val_loss: 1.2383\n",
            "Epoch 60/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8512 - loss: 0.5377 - val_accuracy: 0.7984 - val_loss: 1.2818\n",
            "Epoch 61/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8367 - loss: 0.6822 - val_accuracy: 0.7681 - val_loss: 1.4711\n",
            "Epoch 62/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8395 - loss: 0.5570 - val_accuracy: 0.7359 - val_loss: 1.2353\n",
            "Epoch 63/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 0.4618 - val_accuracy: 0.7440 - val_loss: 1.3039\n",
            "Epoch 64/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 0.4779 - val_accuracy: 0.7641 - val_loss: 1.3160\n",
            "Epoch 65/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 0.5013 - val_accuracy: 0.7762 - val_loss: 1.1281\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7067 - loss: 19.3639 - val_accuracy: 0.7306 - val_loss: 4.6841\n",
            "Epoch 2/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7570 - loss: 3.3349 - val_accuracy: 0.7653 - val_loss: 7.3076\n",
            "Epoch 3/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7827 - loss: 3.3795 - val_accuracy: 0.8143 - val_loss: 4.7459\n",
            "Epoch 4/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 4.0677 - val_accuracy: 0.6122 - val_loss: 4.5175\n",
            "Epoch 5/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7612 - loss: 3.8387 - val_accuracy: 0.8224 - val_loss: 3.4558\n",
            "Epoch 6/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 2.6644 - val_accuracy: 0.7735 - val_loss: 2.9220\n",
            "Epoch 7/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7959 - loss: 2.5058 - val_accuracy: 0.7714 - val_loss: 2.6258\n",
            "Epoch 8/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7952 - loss: 1.1603 - val_accuracy: 0.7612 - val_loss: 3.8850\n",
            "Epoch 9/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7864 - loss: 2.0370 - val_accuracy: 0.7755 - val_loss: 3.6979\n",
            "Epoch 10/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 4.4087 - val_accuracy: 0.7592 - val_loss: 3.5996\n",
            "Epoch 11/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 2.2997 - val_accuracy: 0.8102 - val_loss: 2.4281\n",
            "Epoch 12/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 1.7836 - val_accuracy: 0.7837 - val_loss: 2.7042\n",
            "Epoch 13/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.9909 - val_accuracy: 0.7633 - val_loss: 3.0386\n",
            "Epoch 14/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 1.9600 - val_accuracy: 0.7857 - val_loss: 2.2752\n",
            "Epoch 15/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 1.0419 - val_accuracy: 0.7306 - val_loss: 2.7015\n",
            "Epoch 16/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 2.0869 - val_accuracy: 0.7551 - val_loss: 1.7011\n",
            "Epoch 17/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 1.5634 - val_accuracy: 0.8102 - val_loss: 2.5355\n",
            "Epoch 18/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 1.0117 - val_accuracy: 0.7531 - val_loss: 1.6599\n",
            "Epoch 19/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.8712 - val_accuracy: 0.7837 - val_loss: 3.2535\n",
            "Epoch 20/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.8987 - val_accuracy: 0.7143 - val_loss: 1.9109\n",
            "Epoch 21/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8185 - loss: 1.5756 - val_accuracy: 0.7837 - val_loss: 1.9295\n",
            "Epoch 22/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8161 - loss: 0.8035 - val_accuracy: 0.7490 - val_loss: 3.0944\n",
            "Epoch 23/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8162 - loss: 2.2725 - val_accuracy: 0.7449 - val_loss: 2.9747\n",
            "Epoch 24/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 3.0557 - val_accuracy: 0.7633 - val_loss: 1.9341\n",
            "Epoch 25/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8248 - loss: 0.7733 - val_accuracy: 0.7673 - val_loss: 1.4546\n",
            "Epoch 26/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.6635 - val_accuracy: 0.7898 - val_loss: 1.6760\n",
            "Epoch 27/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.7626 - val_accuracy: 0.7796 - val_loss: 2.7963\n",
            "Epoch 28/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.9376 - val_accuracy: 0.7694 - val_loss: 1.4089\n",
            "Epoch 29/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8217 - loss: 1.2697 - val_accuracy: 0.6551 - val_loss: 2.2577\n",
            "Epoch 30/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.6507 - val_accuracy: 0.7082 - val_loss: 1.3904\n",
            "Epoch 31/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.5831 - val_accuracy: 0.7510 - val_loss: 1.4392\n",
            "Epoch 32/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.6561 - val_accuracy: 0.6816 - val_loss: 1.7660\n",
            "Epoch 33/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.6497 - val_accuracy: 0.7224 - val_loss: 1.3603\n",
            "Epoch 34/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8419 - loss: 0.5529 - val_accuracy: 0.7449 - val_loss: 1.3503\n",
            "Epoch 35/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8316 - loss: 0.6413 - val_accuracy: 0.6510 - val_loss: 2.0546\n",
            "Epoch 36/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.6894 - val_accuracy: 0.7490 - val_loss: 1.3945\n",
            "Epoch 37/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.5521 - val_accuracy: 0.7367 - val_loss: 1.3906\n",
            "Epoch 38/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.5422 - val_accuracy: 0.7245 - val_loss: 1.5430\n",
            "Epoch 39/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8499 - loss: 0.4968 - val_accuracy: 0.7327 - val_loss: 1.4242\n",
            "Epoch 40/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8450 - loss: 0.5167 - val_accuracy: 0.7224 - val_loss: 1.6381\n",
            "Epoch 41/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.5044 - val_accuracy: 0.7449 - val_loss: 1.3996\n",
            "Epoch 42/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8426 - loss: 0.5494 - val_accuracy: 0.7837 - val_loss: 2.5480\n",
            "Epoch 43/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.7562 - val_accuracy: 0.7265 - val_loss: 2.2270\n",
            "Epoch 44/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8408 - loss: 0.6595 - val_accuracy: 0.7633 - val_loss: 1.5905\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5606 - loss: 51.7383 - val_accuracy: 0.5562 - val_loss: 8.3846\n",
            "Epoch 2/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7152 - loss: 4.9771 - val_accuracy: 0.7495 - val_loss: 3.3885\n",
            "Epoch 3/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7398 - loss: 3.5556 - val_accuracy: 0.5010 - val_loss: 4.4470\n",
            "Epoch 4/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 3.4112 - val_accuracy: 0.6410 - val_loss: 4.0503\n",
            "Epoch 5/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7485 - loss: 2.9676 - val_accuracy: 0.5740 - val_loss: 3.7962\n",
            "Epoch 6/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7425 - loss: 2.5045 - val_accuracy: 0.7002 - val_loss: 3.7322\n",
            "Epoch 7/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7389 - loss: 2.6337 - val_accuracy: 0.5878 - val_loss: 5.9126\n",
            "Epoch 8/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7474 - loss: 2.8312 - val_accuracy: 0.5878 - val_loss: 3.9474\n",
            "Epoch 9/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 1.8520 - val_accuracy: 0.7160 - val_loss: 2.6820\n",
            "Epoch 10/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7495 - loss: 1.4890 - val_accuracy: 0.7179 - val_loss: 2.2751\n",
            "Epoch 11/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7698 - loss: 1.1377 - val_accuracy: 0.6647 - val_loss: 2.6332\n",
            "Epoch 12/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 1.3481 - val_accuracy: 0.6923 - val_loss: 2.6191\n",
            "Epoch 13/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 1.6730 - val_accuracy: 0.6252 - val_loss: 2.8639\n",
            "Epoch 14/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7566 - loss: 1.4929 - val_accuracy: 0.6489 - val_loss: 3.0221\n",
            "Epoch 15/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7816 - loss: 1.7671 - val_accuracy: 0.6036 - val_loss: 3.7477\n",
            "Epoch 16/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7683 - loss: 1.4889 - val_accuracy: 0.5523 - val_loss: 3.3349\n",
            "Epoch 17/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 2.1726 - val_accuracy: 0.6548 - val_loss: 2.3023\n",
            "Epoch 18/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 1.4941 - val_accuracy: 0.6726 - val_loss: 2.5519\n",
            "Epoch 19/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 1.4763 - val_accuracy: 0.5247 - val_loss: 3.3709\n",
            "Epoch 20/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7615 - loss: 1.5722 - val_accuracy: 0.5542 - val_loss: 3.1297\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6352 - loss: 40.4863 - val_accuracy: 0.8050 - val_loss: 5.6955\n",
            "Epoch 2/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 5.2288 - val_accuracy: 0.8069 - val_loss: 2.7964\n",
            "Epoch 3/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7551 - loss: 4.4592 - val_accuracy: 0.8147 - val_loss: 3.3116\n",
            "Epoch 4/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7812 - loss: 4.4992 - val_accuracy: 0.8069 - val_loss: 2.4049\n",
            "Epoch 5/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7775 - loss: 1.6671 - val_accuracy: 0.7452 - val_loss: 3.2832\n",
            "Epoch 6/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7925 - loss: 4.3886 - val_accuracy: 0.7992 - val_loss: 2.7484\n",
            "Epoch 7/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7869 - loss: 3.8077 - val_accuracy: 0.6197 - val_loss: 3.9851\n",
            "Epoch 8/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7964 - loss: 3.4257 - val_accuracy: 0.7548 - val_loss: 3.4644\n",
            "Epoch 9/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7897 - loss: 3.7697 - val_accuracy: 0.6139 - val_loss: 2.9833\n",
            "Epoch 10/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 1.8419 - val_accuracy: 0.7239 - val_loss: 1.6395\n",
            "Epoch 11/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 1.2128 - val_accuracy: 0.8147 - val_loss: 2.0254\n",
            "Epoch 12/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 1.1014 - val_accuracy: 0.7124 - val_loss: 2.0518\n",
            "Epoch 13/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 2.8677 - val_accuracy: 0.7375 - val_loss: 1.8467\n",
            "Epoch 14/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 1.2006 - val_accuracy: 0.7201 - val_loss: 2.3677\n",
            "Epoch 15/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 2.8969 - val_accuracy: 0.6853 - val_loss: 3.0215\n",
            "Epoch 16/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 1.5542 - val_accuracy: 0.6506 - val_loss: 2.5419\n",
            "Epoch 17/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.9725 - val_accuracy: 0.7645 - val_loss: 1.3580\n",
            "Epoch 18/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.7178 - val_accuracy: 0.7548 - val_loss: 1.3278\n",
            "Epoch 19/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.7027 - val_accuracy: 0.7162 - val_loss: 1.7212\n",
            "Epoch 20/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.8066 - val_accuracy: 0.6776 - val_loss: 2.8647\n",
            "Epoch 21/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 1.3980 - val_accuracy: 0.6660 - val_loss: 2.2323\n",
            "Epoch 22/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 2.3524 - val_accuracy: 0.7934 - val_loss: 2.3548\n",
            "Epoch 23/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8145 - loss: 1.6044 - val_accuracy: 0.7838 - val_loss: 1.4523\n",
            "Epoch 24/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8148 - loss: 0.9769 - val_accuracy: 0.7336 - val_loss: 1.9281\n",
            "Epoch 25/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 2.2025 - val_accuracy: 0.6969 - val_loss: 1.9867\n",
            "Epoch 26/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8196 - loss: 0.9212 - val_accuracy: 0.6757 - val_loss: 1.6763\n",
            "Epoch 27/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 1.8517 - val_accuracy: 0.6931 - val_loss: 2.0116\n",
            "Epoch 28/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.9629 - val_accuracy: 0.6834 - val_loss: 1.8303\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6028 - loss: 27.7466 - val_accuracy: 0.7280 - val_loss: 7.3408\n",
            "Epoch 2/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 3.2197 - val_accuracy: 0.5418 - val_loss: 7.9533\n",
            "Epoch 3/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7289 - loss: 2.6557 - val_accuracy: 0.4874 - val_loss: 4.5020\n",
            "Epoch 4/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 2.5682 - val_accuracy: 0.5021 - val_loss: 5.2768\n",
            "Epoch 5/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 2.2477 - val_accuracy: 0.5460 - val_loss: 3.0335\n",
            "Epoch 6/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7487 - loss: 1.7839 - val_accuracy: 0.4937 - val_loss: 5.4487\n",
            "Epoch 7/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7342 - loss: 2.0296 - val_accuracy: 0.5126 - val_loss: 3.4014\n",
            "Epoch 8/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7295 - loss: 1.9641 - val_accuracy: 0.5314 - val_loss: 5.1316\n",
            "Epoch 9/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7562 - loss: 1.6502 - val_accuracy: 0.7113 - val_loss: 3.1244\n",
            "Epoch 10/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7255 - loss: 2.0900 - val_accuracy: 0.7448 - val_loss: 2.0332\n",
            "Epoch 11/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 1.4321 - val_accuracy: 0.5314 - val_loss: 3.7537\n",
            "Epoch 12/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7502 - loss: 1.7793 - val_accuracy: 0.6715 - val_loss: 3.7620\n",
            "Epoch 13/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 1.4832 - val_accuracy: 0.5669 - val_loss: 3.2798\n",
            "Epoch 14/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7524 - loss: 1.3053 - val_accuracy: 0.6464 - val_loss: 2.2061\n",
            "Epoch 15/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7628 - loss: 1.1593 - val_accuracy: 0.6674 - val_loss: 1.7064\n",
            "Epoch 16/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7623 - loss: 1.0876 - val_accuracy: 0.6151 - val_loss: 2.9194\n",
            "Epoch 17/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 1.0953 - val_accuracy: 0.5481 - val_loss: 2.1911\n",
            "Epoch 18/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7496 - loss: 1.2728 - val_accuracy: 0.6632 - val_loss: 1.8845\n",
            "Epoch 19/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.7842 - val_accuracy: 0.6506 - val_loss: 1.5208\n",
            "Epoch 20/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.7782 - val_accuracy: 0.6360 - val_loss: 2.3293\n",
            "Epoch 21/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7808 - loss: 0.9068 - val_accuracy: 0.6527 - val_loss: 1.7337\n",
            "Epoch 22/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 1.0521 - val_accuracy: 0.7071 - val_loss: 3.1095\n",
            "Epoch 23/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 1.1782 - val_accuracy: 0.6130 - val_loss: 2.2894\n",
            "Epoch 24/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.8977 - val_accuracy: 0.7238 - val_loss: 1.6218\n",
            "Epoch 25/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7773 - loss: 0.8903 - val_accuracy: 0.7008 - val_loss: 2.5216\n",
            "Epoch 26/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.9971 - val_accuracy: 0.7092 - val_loss: 1.2811\n",
            "Epoch 27/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7941 - loss: 0.7769 - val_accuracy: 0.6276 - val_loss: 2.1358\n",
            "Epoch 28/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.9724 - val_accuracy: 0.6736 - val_loss: 1.9294\n",
            "Epoch 29/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 1.1303 - val_accuracy: 0.6925 - val_loss: 2.0021\n",
            "Epoch 30/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.7329 - val_accuracy: 0.7029 - val_loss: 1.6792\n",
            "Epoch 31/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.7413 - val_accuracy: 0.6862 - val_loss: 1.7852\n",
            "Epoch 32/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.7316 - val_accuracy: 0.7238 - val_loss: 1.5909\n",
            "Epoch 33/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.6148 - val_accuracy: 0.7594 - val_loss: 1.3560\n",
            "Epoch 34/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.6241 - val_accuracy: 0.7510 - val_loss: 1.4555\n",
            "Epoch 35/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.6928 - val_accuracy: 0.7218 - val_loss: 1.5234\n",
            "Epoch 36/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.7113 - val_accuracy: 0.6967 - val_loss: 2.2173\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Average AUC: 0.6675724983215332\n",
            "Average Kappa: 0.13152523413544312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration B - 1 Hidden Layer\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Masking, Dense, LSTM, TimeDistributed, Dropout, Normalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
        "\n",
        "# Set a seed value\n",
        "seed_value= 42\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "auc_scores = []\n",
        "kappa_scores = []\n",
        "\n",
        "for fold in np.unique(fold_nonrecurrent):\n",
        "    training = np.argwhere(fold_nonrecurrent != fold).ravel()\n",
        "    testing = np.argwhere(fold_nonrecurrent == fold).ravel()\n",
        "\n",
        "    X_train, X_test = X_nonrecurrent[training], X_nonrecurrent[testing]\n",
        "    y_train, y_test = y_nonrecurrent[training], y_nonrecurrent[testing]\n",
        "\n",
        "    # Define the model\n",
        "    keras.backend.clear_session()\n",
        "    model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(92,)),\n",
        "    Dense(4, activation='softmax')  # Remove the 64-node layer\n",
        "])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model with the new training and validation sets\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=100,\n",
        "                        validation_split=0.2,\n",
        "                        verbose=1, # setting this to 0 reduces the amount printed\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "     # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # AUC\n",
        "    auc_score = auc(y_test, y_pred)\n",
        "\n",
        "    # Kappa Score\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    kappa_score = cohen_kappa_score(y_true_classes, y_pred_classes)\n",
        "\n",
        "    auc_scores.append(auc_score)\n",
        "    kappa_scores.append(kappa_score)\n",
        "\n",
        "# Calculate the average AUC and Kappa scores across all folds\n",
        "average_auc = np.mean(auc_scores)\n",
        "average_kappa = np.mean(kappa_scores)\n",
        "\n",
        "print(f\"Average AUC: {average_auc}\")\n",
        "print(f\"Average Kappa: {average_kappa}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjZD6ppfjsXD",
        "outputId": "5b783b7c-2615-4155-8664-63b38e985c74"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7128 - loss: 20.0671 - val_accuracy: 0.6290 - val_loss: 8.0004\n",
            "Epoch 2/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7527 - loss: 3.3842 - val_accuracy: 0.7379 - val_loss: 5.6998\n",
            "Epoch 3/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 3.2693 - val_accuracy: 0.7056 - val_loss: 4.9966\n",
            "Epoch 4/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7624 - loss: 2.8926 - val_accuracy: 0.7198 - val_loss: 3.3671\n",
            "Epoch 5/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7727 - loss: 1.8512 - val_accuracy: 0.7339 - val_loss: 3.1597\n",
            "Epoch 6/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7743 - loss: 2.0355 - val_accuracy: 0.6391 - val_loss: 4.8288\n",
            "Epoch 7/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7645 - loss: 2.0432 - val_accuracy: 0.7641 - val_loss: 4.1906\n",
            "Epoch 8/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7713 - loss: 2.2962 - val_accuracy: 0.7581 - val_loss: 4.2177\n",
            "Epoch 9/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 2.6263 - val_accuracy: 0.6875 - val_loss: 5.8079\n",
            "Epoch 10/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7690 - loss: 2.5813 - val_accuracy: 0.7722 - val_loss: 4.0726\n",
            "Epoch 11/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 2.2663 - val_accuracy: 0.6915 - val_loss: 3.5191\n",
            "Epoch 12/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 1.7344 - val_accuracy: 0.7621 - val_loss: 2.5899\n",
            "Epoch 13/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 1.3835 - val_accuracy: 0.7742 - val_loss: 2.1345\n",
            "Epoch 14/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 1.8106 - val_accuracy: 0.7399 - val_loss: 2.4698\n",
            "Epoch 15/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 1.5760 - val_accuracy: 0.7500 - val_loss: 2.2204\n",
            "Epoch 16/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 1.5071 - val_accuracy: 0.7379 - val_loss: 3.5330\n",
            "Epoch 17/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 1.8462 - val_accuracy: 0.7016 - val_loss: 3.7911\n",
            "Epoch 18/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 1.5284 - val_accuracy: 0.6875 - val_loss: 3.0039\n",
            "Epoch 19/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 1.5659 - val_accuracy: 0.6915 - val_loss: 3.4326\n",
            "Epoch 20/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 1.5767 - val_accuracy: 0.7722 - val_loss: 2.2791\n",
            "Epoch 21/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 1.7396 - val_accuracy: 0.6935 - val_loss: 3.2107\n",
            "Epoch 22/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7918 - loss: 1.4321 - val_accuracy: 0.7177 - val_loss: 3.6909\n",
            "Epoch 23/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7728 - loss: 2.7830 - val_accuracy: 0.6411 - val_loss: 6.3981\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7082 - loss: 13.0154 - val_accuracy: 0.8020 - val_loss: 4.5278\n",
            "Epoch 2/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 4.2760 - val_accuracy: 0.7816 - val_loss: 5.6766\n",
            "Epoch 3/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 2.5381 - val_accuracy: 0.8347 - val_loss: 4.4435\n",
            "Epoch 4/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7670 - loss: 4.1995 - val_accuracy: 0.6347 - val_loss: 4.3873\n",
            "Epoch 5/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7755 - loss: 3.7790 - val_accuracy: 0.8286 - val_loss: 4.1906\n",
            "Epoch 6/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 2.9980 - val_accuracy: 0.7878 - val_loss: 3.0110\n",
            "Epoch 7/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 2.6999 - val_accuracy: 0.7612 - val_loss: 3.7970\n",
            "Epoch 8/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 3.1343 - val_accuracy: 0.6837 - val_loss: 3.8425\n",
            "Epoch 9/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7922 - loss: 2.4695 - val_accuracy: 0.7633 - val_loss: 2.8785\n",
            "Epoch 10/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7914 - loss: 1.4113 - val_accuracy: 0.6735 - val_loss: 2.9869\n",
            "Epoch 11/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 2.8558 - val_accuracy: 0.7612 - val_loss: 2.7044\n",
            "Epoch 12/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 1.4244 - val_accuracy: 0.7306 - val_loss: 2.1349\n",
            "Epoch 13/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7928 - loss: 1.3336 - val_accuracy: 0.7816 - val_loss: 3.7919\n",
            "Epoch 14/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7934 - loss: 2.8089 - val_accuracy: 0.7490 - val_loss: 3.4981\n",
            "Epoch 15/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 2.8829 - val_accuracy: 0.6510 - val_loss: 4.3876\n",
            "Epoch 16/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7860 - loss: 1.8081 - val_accuracy: 0.6224 - val_loss: 2.9994\n",
            "Epoch 17/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 1.4438 - val_accuracy: 0.8000 - val_loss: 2.3551\n",
            "Epoch 18/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 1.2100 - val_accuracy: 0.7408 - val_loss: 2.6075\n",
            "Epoch 19/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7978 - loss: 1.3457 - val_accuracy: 0.6429 - val_loss: 3.0985\n",
            "Epoch 20/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 1.6653 - val_accuracy: 0.6755 - val_loss: 2.5223\n",
            "Epoch 21/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 1.2170 - val_accuracy: 0.6857 - val_loss: 4.0153\n",
            "Epoch 22/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 1.6613 - val_accuracy: 0.8061 - val_loss: 2.4756\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7104 - loss: 31.6141 - val_accuracy: 0.5424 - val_loss: 8.4322\n",
            "Epoch 2/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7225 - loss: 6.1948 - val_accuracy: 0.6312 - val_loss: 5.3135\n",
            "Epoch 3/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7294 - loss: 4.5145 - val_accuracy: 0.5582 - val_loss: 5.2471\n",
            "Epoch 4/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 4.1544 - val_accuracy: 0.4951 - val_loss: 5.1849\n",
            "Epoch 5/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7472 - loss: 3.6974 - val_accuracy: 0.5128 - val_loss: 4.3685\n",
            "Epoch 6/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 3.4876 - val_accuracy: 0.4103 - val_loss: 5.3059\n",
            "Epoch 7/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7507 - loss: 3.2268 - val_accuracy: 0.4813 - val_loss: 5.1731\n",
            "Epoch 8/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 2.3193 - val_accuracy: 0.6667 - val_loss: 3.6865\n",
            "Epoch 9/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 2.9494 - val_accuracy: 0.4990 - val_loss: 6.0334\n",
            "Epoch 10/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 2.8523 - val_accuracy: 0.4043 - val_loss: 4.7359\n",
            "Epoch 11/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7418 - loss: 3.0560 - val_accuracy: 0.4004 - val_loss: 6.5104\n",
            "Epoch 12/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 2.6157 - val_accuracy: 0.6292 - val_loss: 4.1062\n",
            "Epoch 13/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7614 - loss: 2.0607 - val_accuracy: 0.6312 - val_loss: 4.7136\n",
            "Epoch 14/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7606 - loss: 2.3117 - val_accuracy: 0.6351 - val_loss: 4.2700\n",
            "Epoch 15/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 2.0462 - val_accuracy: 0.5385 - val_loss: 5.0734\n",
            "Epoch 16/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 1.9575 - val_accuracy: 0.6588 - val_loss: 3.2180\n",
            "Epoch 17/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 1.6817 - val_accuracy: 0.6036 - val_loss: 3.4831\n",
            "Epoch 18/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7612 - loss: 2.4501 - val_accuracy: 0.5819 - val_loss: 5.7579\n",
            "Epoch 19/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 2.0906 - val_accuracy: 0.7278 - val_loss: 2.6953\n",
            "Epoch 20/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7763 - loss: 2.0217 - val_accuracy: 0.6391 - val_loss: 4.9978\n",
            "Epoch 21/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 1.6807 - val_accuracy: 0.6509 - val_loss: 3.3091\n",
            "Epoch 22/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7792 - loss: 1.7332 - val_accuracy: 0.5799 - val_loss: 4.0636\n",
            "Epoch 23/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7693 - loss: 2.1396 - val_accuracy: 0.6686 - val_loss: 4.3415\n",
            "Epoch 24/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7631 - loss: 2.9006 - val_accuracy: 0.5661 - val_loss: 5.0736\n",
            "Epoch 25/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 1.8817 - val_accuracy: 0.6864 - val_loss: 3.2778\n",
            "Epoch 26/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 1.9465 - val_accuracy: 0.6351 - val_loss: 3.1207\n",
            "Epoch 27/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 1.3707 - val_accuracy: 0.6233 - val_loss: 3.2774\n",
            "Epoch 28/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 1.5192 - val_accuracy: 0.6785 - val_loss: 2.6290\n",
            "Epoch 29/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 1.2330 - val_accuracy: 0.6943 - val_loss: 2.7288\n",
            "Epoch 30/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 1.6538 - val_accuracy: 0.5799 - val_loss: 2.7829\n",
            "Epoch 31/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7864 - loss: 1.2027 - val_accuracy: 0.6174 - val_loss: 3.1444\n",
            "Epoch 32/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 1.3371 - val_accuracy: 0.6963 - val_loss: 2.9279\n",
            "Epoch 33/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7906 - loss: 1.5029 - val_accuracy: 0.6884 - val_loss: 2.8981\n",
            "Epoch 34/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 2.8523 - val_accuracy: 0.5799 - val_loss: 5.2442\n",
            "Epoch 35/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 2.0019 - val_accuracy: 0.6450 - val_loss: 2.7988\n",
            "Epoch 36/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 2.1512 - val_accuracy: 0.5621 - val_loss: 3.8906\n",
            "Epoch 37/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7679 - loss: 2.0545 - val_accuracy: 0.5049 - val_loss: 4.2426\n",
            "Epoch 38/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7633 - loss: 2.3914 - val_accuracy: 0.3629 - val_loss: 5.1551\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6914 - loss: 19.3309 - val_accuracy: 0.8031 - val_loss: 3.5338\n",
            "Epoch 2/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 5.2558 - val_accuracy: 0.5560 - val_loss: 8.4120\n",
            "Epoch 3/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7465 - loss: 5.3957 - val_accuracy: 0.7722 - val_loss: 2.8207\n",
            "Epoch 4/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 3.2123 - val_accuracy: 0.5483 - val_loss: 4.0421\n",
            "Epoch 5/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7694 - loss: 2.7883 - val_accuracy: 0.7375 - val_loss: 3.7383\n",
            "Epoch 6/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7776 - loss: 2.2442 - val_accuracy: 0.7954 - val_loss: 3.0060\n",
            "Epoch 7/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 3.1472 - val_accuracy: 0.7510 - val_loss: 3.2902\n",
            "Epoch 8/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7729 - loss: 3.0401 - val_accuracy: 0.7625 - val_loss: 4.0946\n",
            "Epoch 9/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7560 - loss: 3.6739 - val_accuracy: 0.7683 - val_loss: 3.6155\n",
            "Epoch 10/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 2.7142 - val_accuracy: 0.7259 - val_loss: 2.7225\n",
            "Epoch 11/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 1.4847 - val_accuracy: 0.8263 - val_loss: 2.0637\n",
            "Epoch 12/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 1.8146 - val_accuracy: 0.7683 - val_loss: 1.9733\n",
            "Epoch 13/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 1.4959 - val_accuracy: 0.8050 - val_loss: 2.6354\n",
            "Epoch 14/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 2.4128 - val_accuracy: 0.7838 - val_loss: 3.4778\n",
            "Epoch 15/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 1.7919 - val_accuracy: 0.6371 - val_loss: 3.3087\n",
            "Epoch 16/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 2.6162 - val_accuracy: 0.7375 - val_loss: 2.7409\n",
            "Epoch 17/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 1.9223 - val_accuracy: 0.8224 - val_loss: 1.9144\n",
            "Epoch 18/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 1.4832 - val_accuracy: 0.6429 - val_loss: 3.8246\n",
            "Epoch 19/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 1.6855 - val_accuracy: 0.6911 - val_loss: 2.5006\n",
            "Epoch 20/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 1.4933 - val_accuracy: 0.7722 - val_loss: 2.1861\n",
            "Epoch 21/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 1.4608 - val_accuracy: 0.8320 - val_loss: 2.1485\n",
            "Epoch 22/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 1.4385 - val_accuracy: 0.6583 - val_loss: 3.4468\n",
            "Epoch 23/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 2.7924 - val_accuracy: 0.7143 - val_loss: 2.3154\n",
            "Epoch 24/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 1.1776 - val_accuracy: 0.8127 - val_loss: 3.1888\n",
            "Epoch 25/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 2.5799 - val_accuracy: 0.7066 - val_loss: 2.9148\n",
            "Epoch 26/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 1.4850 - val_accuracy: 0.8050 - val_loss: 2.5355\n",
            "Epoch 27/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 1.6101 - val_accuracy: 0.7876 - val_loss: 3.8378\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6143 - loss: 16.6521 - val_accuracy: 0.6778 - val_loss: 11.0446\n",
            "Epoch 2/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7262 - loss: 4.4409 - val_accuracy: 0.5105 - val_loss: 6.5534\n",
            "Epoch 3/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7214 - loss: 3.1237 - val_accuracy: 0.6360 - val_loss: 7.8256\n",
            "Epoch 4/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 2.8205 - val_accuracy: 0.5418 - val_loss: 5.6384\n",
            "Epoch 5/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 2.0574 - val_accuracy: 0.5021 - val_loss: 5.9546\n",
            "Epoch 6/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 2.4687 - val_accuracy: 0.6548 - val_loss: 7.6813\n",
            "Epoch 7/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7569 - loss: 2.1898 - val_accuracy: 0.5900 - val_loss: 3.9268\n",
            "Epoch 8/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7468 - loss: 1.6304 - val_accuracy: 0.7531 - val_loss: 5.3838\n",
            "Epoch 9/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7520 - loss: 2.0731 - val_accuracy: 0.6318 - val_loss: 3.0144\n",
            "Epoch 10/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7699 - loss: 1.4704 - val_accuracy: 0.5816 - val_loss: 7.6454\n",
            "Epoch 11/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 2.1206 - val_accuracy: 0.6527 - val_loss: 4.4553\n",
            "Epoch 12/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7613 - loss: 1.7860 - val_accuracy: 0.6381 - val_loss: 3.8953\n",
            "Epoch 13/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7667 - loss: 1.6505 - val_accuracy: 0.6715 - val_loss: 4.4371\n",
            "Epoch 14/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7677 - loss: 1.3897 - val_accuracy: 0.7238 - val_loss: 3.0137\n",
            "Epoch 15/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 1.2463 - val_accuracy: 0.6423 - val_loss: 2.4390\n",
            "Epoch 16/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 1.3140 - val_accuracy: 0.6381 - val_loss: 2.9450\n",
            "Epoch 17/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7784 - loss: 1.3154 - val_accuracy: 0.6799 - val_loss: 2.8909\n",
            "Epoch 18/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7671 - loss: 1.3429 - val_accuracy: 0.5774 - val_loss: 4.9435\n",
            "Epoch 19/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7699 - loss: 2.1545 - val_accuracy: 0.5983 - val_loss: 3.4263\n",
            "Epoch 20/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7425 - loss: 1.6585 - val_accuracy: 0.6464 - val_loss: 3.6213\n",
            "Epoch 21/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7691 - loss: 1.1096 - val_accuracy: 0.7448 - val_loss: 3.9554\n",
            "Epoch 22/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 1.0834 - val_accuracy: 0.6444 - val_loss: 2.4821\n",
            "Epoch 23/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7664 - loss: 1.0123 - val_accuracy: 0.5962 - val_loss: 3.1788\n",
            "Epoch 24/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 1.0654 - val_accuracy: 0.6967 - val_loss: 2.6540\n",
            "Epoch 25/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7646 - loss: 1.2541 - val_accuracy: 0.5816 - val_loss: 3.6381\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Average AUC: 0.6328721046447754\n",
            "Average Kappa: 0.09604215024791445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration C - 2 Hidden Layers with Tanh Activation\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Masking, Dense, LSTM, TimeDistributed, Dropout, Normalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
        "\n",
        "# Set a seed value\n",
        "seed_value= 42\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "auc_scores = []\n",
        "kappa_scores = []\n",
        "\n",
        "for fold in np.unique(fold_nonrecurrent):\n",
        "    training = np.argwhere(fold_nonrecurrent != fold).ravel()\n",
        "    testing = np.argwhere(fold_nonrecurrent == fold).ravel()\n",
        "\n",
        "    X_train, X_test = X_nonrecurrent[training], X_nonrecurrent[testing]\n",
        "    y_train, y_test = y_nonrecurrent[training], y_nonrecurrent[testing]\n",
        "\n",
        "    # Define the model\n",
        "    keras.backend.clear_session()\n",
        "    model = Sequential([  # ← This line needs proper indentation!\n",
        "        Dense(128, activation='tanh', input_shape=(92,)),\n",
        "        Dense(64, activation='tanh'),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model with the new training and validation sets\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=100,\n",
        "                        validation_split=0.2,\n",
        "                        verbose=1,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "     # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # AUC\n",
        "    auc_score = auc(y_test, y_pred)\n",
        "\n",
        "    # Kappa Score\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    kappa_score = cohen_kappa_score(y_true_classes, y_pred_classes)\n",
        "\n",
        "    auc_scores.append(auc_score)\n",
        "    kappa_scores.append(kappa_score)\n",
        "\n",
        "# Calculate the average AUC and Kappa scores across all folds\n",
        "average_auc = np.mean(auc_scores)\n",
        "average_kappa = np.mean(kappa_scores)\n",
        "\n",
        "print(f\"Average AUC: {average_auc}\")\n",
        "print(f\"Average Kappa: {average_kappa}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qm4EQqCl0Ly",
        "outputId": "5cf179f8-53c6-4f87-9bb0-d4f495278981"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7538 - loss: 0.7287 - val_accuracy: 0.8246 - val_loss: 0.6804\n",
            "Epoch 2/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.5771 - val_accuracy: 0.8185 - val_loss: 0.6548\n",
            "Epoch 3/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.5698 - val_accuracy: 0.8185 - val_loss: 0.6650\n",
            "Epoch 4/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.5580 - val_accuracy: 0.8266 - val_loss: 0.6706\n",
            "Epoch 5/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.5569 - val_accuracy: 0.8246 - val_loss: 0.6555\n",
            "Epoch 6/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8344 - loss: 0.5517 - val_accuracy: 0.8306 - val_loss: 0.6587\n",
            "Epoch 7/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.5420 - val_accuracy: 0.8286 - val_loss: 0.6536\n",
            "Epoch 8/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8374 - loss: 0.5365 - val_accuracy: 0.8286 - val_loss: 0.6645\n",
            "Epoch 9/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.5398 - val_accuracy: 0.8246 - val_loss: 0.6620\n",
            "Epoch 10/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8347 - loss: 0.5376 - val_accuracy: 0.8286 - val_loss: 0.6505\n",
            "Epoch 11/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8362 - loss: 0.5403 - val_accuracy: 0.8226 - val_loss: 0.6612\n",
            "Epoch 12/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8401 - loss: 0.5273 - val_accuracy: 0.8266 - val_loss: 0.6786\n",
            "Epoch 13/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8379 - loss: 0.5200 - val_accuracy: 0.8246 - val_loss: 0.6800\n",
            "Epoch 14/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.5259 - val_accuracy: 0.8246 - val_loss: 0.6830\n",
            "Epoch 15/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8417 - loss: 0.5213 - val_accuracy: 0.8246 - val_loss: 0.6776\n",
            "Epoch 16/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.5196 - val_accuracy: 0.8246 - val_loss: 0.6753\n",
            "Epoch 17/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8412 - loss: 0.5223 - val_accuracy: 0.8286 - val_loss: 0.6855\n",
            "Epoch 18/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.5173 - val_accuracy: 0.8286 - val_loss: 0.6833\n",
            "Epoch 19/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8435 - loss: 0.5113 - val_accuracy: 0.8286 - val_loss: 0.6758\n",
            "Epoch 20/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.5121 - val_accuracy: 0.8226 - val_loss: 0.6828\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6931 - loss: 0.9149 - val_accuracy: 0.8224 - val_loss: 0.6694\n",
            "Epoch 2/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.5523 - val_accuracy: 0.8204 - val_loss: 0.6689\n",
            "Epoch 3/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.5381 - val_accuracy: 0.8204 - val_loss: 0.6744\n",
            "Epoch 4/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8290 - loss: 0.5348 - val_accuracy: 0.8286 - val_loss: 0.6771\n",
            "Epoch 5/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8278 - loss: 0.5173 - val_accuracy: 0.8245 - val_loss: 0.6846\n",
            "Epoch 6/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.5144 - val_accuracy: 0.8204 - val_loss: 0.6793\n",
            "Epoch 7/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.5113 - val_accuracy: 0.8286 - val_loss: 0.6776\n",
            "Epoch 8/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.5111 - val_accuracy: 0.8327 - val_loss: 0.6695\n",
            "Epoch 9/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8299 - loss: 0.5098 - val_accuracy: 0.8306 - val_loss: 0.6731\n",
            "Epoch 10/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.4998 - val_accuracy: 0.8306 - val_loss: 0.6812\n",
            "Epoch 11/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.4946 - val_accuracy: 0.8265 - val_loss: 0.6731\n",
            "Epoch 12/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.4892 - val_accuracy: 0.8327 - val_loss: 0.6762\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7526 - loss: 0.7468 - val_accuracy: 0.8304 - val_loss: 0.6655\n",
            "Epoch 2/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8130 - loss: 0.6193 - val_accuracy: 0.8304 - val_loss: 0.6471\n",
            "Epoch 3/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8170 - loss: 0.6125 - val_accuracy: 0.8304 - val_loss: 0.6428\n",
            "Epoch 4/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.6006 - val_accuracy: 0.8245 - val_loss: 0.6451\n",
            "Epoch 5/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.6004 - val_accuracy: 0.8245 - val_loss: 0.6526\n",
            "Epoch 6/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.5911 - val_accuracy: 0.8284 - val_loss: 0.6596\n",
            "Epoch 7/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.5812 - val_accuracy: 0.8264 - val_loss: 0.6539\n",
            "Epoch 8/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.5812 - val_accuracy: 0.8284 - val_loss: 0.6572\n",
            "Epoch 9/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.5779 - val_accuracy: 0.8264 - val_loss: 0.6611\n",
            "Epoch 10/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.5805 - val_accuracy: 0.8185 - val_loss: 0.6650\n",
            "Epoch 11/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8213 - loss: 0.5708 - val_accuracy: 0.8245 - val_loss: 0.6637\n",
            "Epoch 12/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.5640 - val_accuracy: 0.8264 - val_loss: 0.6737\n",
            "Epoch 13/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.5667 - val_accuracy: 0.8225 - val_loss: 0.6782\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6858 - loss: 0.8912 - val_accuracy: 0.8533 - val_loss: 0.6202\n",
            "Epoch 2/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8325 - loss: 0.5673 - val_accuracy: 0.8533 - val_loss: 0.6363\n",
            "Epoch 3/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.5617 - val_accuracy: 0.8552 - val_loss: 0.6362\n",
            "Epoch 4/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.5493 - val_accuracy: 0.8552 - val_loss: 0.6436\n",
            "Epoch 5/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.5396 - val_accuracy: 0.8552 - val_loss: 0.6374\n",
            "Epoch 6/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8395 - loss: 0.5316 - val_accuracy: 0.8533 - val_loss: 0.6456\n",
            "Epoch 7/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.5309 - val_accuracy: 0.8475 - val_loss: 0.6601\n",
            "Epoch 8/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8339 - loss: 0.5253 - val_accuracy: 0.8514 - val_loss: 0.6528\n",
            "Epoch 9/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8367 - loss: 0.5227 - val_accuracy: 0.8456 - val_loss: 0.6601\n",
            "Epoch 10/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.5214 - val_accuracy: 0.8514 - val_loss: 0.6552\n",
            "Epoch 11/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8379 - loss: 0.5170 - val_accuracy: 0.8436 - val_loss: 0.6544\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7328 - loss: 0.8360 - val_accuracy: 0.7845 - val_loss: 0.7894\n",
            "Epoch 2/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8043 - loss: 0.6162 - val_accuracy: 0.7845 - val_loss: 0.8105\n",
            "Epoch 3/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.6017 - val_accuracy: 0.7845 - val_loss: 0.8181\n",
            "Epoch 4/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.5911 - val_accuracy: 0.7845 - val_loss: 0.8148\n",
            "Epoch 5/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.5892 - val_accuracy: 0.7845 - val_loss: 0.8068\n",
            "Epoch 6/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.5795 - val_accuracy: 0.7866 - val_loss: 0.8120\n",
            "Epoch 7/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.5740 - val_accuracy: 0.7866 - val_loss: 0.8197\n",
            "Epoch 8/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.5716 - val_accuracy: 0.7845 - val_loss: 0.8197\n",
            "Epoch 9/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.5669 - val_accuracy: 0.7866 - val_loss: 0.8223\n",
            "Epoch 10/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.5522 - val_accuracy: 0.7866 - val_loss: 0.8234\n",
            "Epoch 11/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.5506 - val_accuracy: 0.7908 - val_loss: 0.8454\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Average AUC: 0.6540877223014832\n",
            "Average Kappa: 0.04822608187054618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration D - 3 Hidden Layers with Mixed Activations\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Masking, Dense, LSTM, TimeDistributed, Dropout, Normalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
        "\n",
        "# Set a seed value\n",
        "seed_value= 42\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "auc_scores = []\n",
        "kappa_scores = []\n",
        "\n",
        "for fold in np.unique(fold_nonrecurrent):\n",
        "    training = np.argwhere(fold_nonrecurrent != fold).ravel()\n",
        "    testing = np.argwhere(fold_nonrecurrent == fold).ravel()\n",
        "\n",
        "    X_train, X_test = X_nonrecurrent[training], X_nonrecurrent[testing]\n",
        "    y_train, y_test = y_nonrecurrent[training], y_nonrecurrent[testing]\n",
        "\n",
        "    # Define the model\n",
        "    keras.backend.clear_session()  # ← Fixed indentation\n",
        "    model = Sequential([           # ← Fixed indentation\n",
        "        Dense(64, activation='relu', input_shape=(92,)),\n",
        "        Dense(64, activation='tanh'),\n",
        "        Dense(32, activation='tanh'),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model with the new training and validation sets\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=100,\n",
        "                        validation_split=0.2,\n",
        "                        verbose=1,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "     # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # AUC\n",
        "    auc_score = auc(y_test, y_pred)\n",
        "\n",
        "    # Kappa Score\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    kappa_score = cohen_kappa_score(y_true_classes, y_pred_classes)\n",
        "\n",
        "    auc_scores.append(auc_score)\n",
        "    kappa_scores.append(kappa_score)\n",
        "\n",
        "# Calculate the average AUC and Kappa scores across all folds\n",
        "average_auc = np.mean(auc_scores)\n",
        "average_kappa = np.mean(kappa_scores)\n",
        "\n",
        "print(f\"Average AUC: {average_auc}\")\n",
        "print(f\"Average Kappa: {average_kappa}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpXfcL9fnqUP",
        "outputId": "aa087a39-2fcb-48b1-865d-2132afaf7b7e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7493 - loss: 0.7604 - val_accuracy: 0.8306 - val_loss: 0.6506\n",
            "Epoch 2/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8339 - loss: 0.5753 - val_accuracy: 0.8327 - val_loss: 0.6624\n",
            "Epoch 3/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8344 - loss: 0.5709 - val_accuracy: 0.8327 - val_loss: 0.6443\n",
            "Epoch 4/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8345 - loss: 0.5650 - val_accuracy: 0.8367 - val_loss: 0.6464\n",
            "Epoch 5/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.5555 - val_accuracy: 0.8347 - val_loss: 0.6411\n",
            "Epoch 6/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.5554 - val_accuracy: 0.8327 - val_loss: 0.6479\n",
            "Epoch 7/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.5542 - val_accuracy: 0.8327 - val_loss: 0.6472\n",
            "Epoch 8/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8349 - loss: 0.5581 - val_accuracy: 0.8306 - val_loss: 0.6444\n",
            "Epoch 9/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8346 - loss: 0.5672 - val_accuracy: 0.8327 - val_loss: 0.6465\n",
            "Epoch 10/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8349 - loss: 0.5625 - val_accuracy: 0.8347 - val_loss: 0.6554\n",
            "Epoch 11/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8341 - loss: 0.5585 - val_accuracy: 0.8306 - val_loss: 0.6371\n",
            "Epoch 12/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8353 - loss: 0.5616 - val_accuracy: 0.8327 - val_loss: 0.6544\n",
            "Epoch 13/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.5628 - val_accuracy: 0.8327 - val_loss: 0.6452\n",
            "Epoch 14/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8351 - loss: 0.5632 - val_accuracy: 0.8306 - val_loss: 0.6505\n",
            "Epoch 15/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - loss: 0.5603 - val_accuracy: 0.8306 - val_loss: 0.6468\n",
            "Epoch 16/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.5666 - val_accuracy: 0.8327 - val_loss: 0.6400\n",
            "Epoch 17/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.5615 - val_accuracy: 0.8306 - val_loss: 0.6479\n",
            "Epoch 18/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.5538 - val_accuracy: 0.8327 - val_loss: 0.6448\n",
            "Epoch 19/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8356 - loss: 0.5539 - val_accuracy: 0.8306 - val_loss: 0.6444\n",
            "Epoch 20/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8348 - loss: 0.5546 - val_accuracy: 0.8306 - val_loss: 0.6418\n",
            "Epoch 21/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.5501 - val_accuracy: 0.8327 - val_loss: 0.6469\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6894 - loss: 0.8584 - val_accuracy: 0.8367 - val_loss: 0.6555\n",
            "Epoch 2/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8311 - loss: 0.5672 - val_accuracy: 0.8367 - val_loss: 0.6714\n",
            "Epoch 3/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.5562 - val_accuracy: 0.8367 - val_loss: 0.6609\n",
            "Epoch 4/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.5535 - val_accuracy: 0.8367 - val_loss: 0.6825\n",
            "Epoch 5/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.5486 - val_accuracy: 0.8367 - val_loss: 0.6685\n",
            "Epoch 6/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8319 - loss: 0.5552 - val_accuracy: 0.8367 - val_loss: 0.6705\n",
            "Epoch 7/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.5480 - val_accuracy: 0.8367 - val_loss: 0.6700\n",
            "Epoch 8/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.5418 - val_accuracy: 0.8367 - val_loss: 0.6729\n",
            "Epoch 9/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.5366 - val_accuracy: 0.8367 - val_loss: 0.6693\n",
            "Epoch 10/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 0.5382 - val_accuracy: 0.8347 - val_loss: 0.6956\n",
            "Epoch 11/100\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.5462 - val_accuracy: 0.8367 - val_loss: 0.6642\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.8087 - val_accuracy: 0.8343 - val_loss: 0.6377\n",
            "Epoch 2/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8169 - loss: 0.6327 - val_accuracy: 0.8343 - val_loss: 0.6397\n",
            "Epoch 3/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8162 - loss: 0.6170 - val_accuracy: 0.8343 - val_loss: 0.6395\n",
            "Epoch 4/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8166 - loss: 0.6242 - val_accuracy: 0.8343 - val_loss: 0.6312\n",
            "Epoch 5/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.6203 - val_accuracy: 0.8304 - val_loss: 0.6477\n",
            "Epoch 6/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.6231 - val_accuracy: 0.8343 - val_loss: 0.6401\n",
            "Epoch 7/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.6253 - val_accuracy: 0.8264 - val_loss: 0.6399\n",
            "Epoch 8/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.6184 - val_accuracy: 0.8343 - val_loss: 0.6240\n",
            "Epoch 9/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.6139 - val_accuracy: 0.8343 - val_loss: 0.6395\n",
            "Epoch 10/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.6064 - val_accuracy: 0.8304 - val_loss: 0.6472\n",
            "Epoch 11/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.6104 - val_accuracy: 0.8304 - val_loss: 0.6331\n",
            "Epoch 12/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.6110 - val_accuracy: 0.8304 - val_loss: 0.6362\n",
            "Epoch 13/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.6126 - val_accuracy: 0.8304 - val_loss: 0.6444\n",
            "Epoch 14/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8116 - loss: 0.6150 - val_accuracy: 0.8343 - val_loss: 0.6377\n",
            "Epoch 15/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.6175 - val_accuracy: 0.8284 - val_loss: 0.6484\n",
            "Epoch 16/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.6163 - val_accuracy: 0.8304 - val_loss: 0.6556\n",
            "Epoch 17/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.6119 - val_accuracy: 0.8323 - val_loss: 0.6555\n",
            "Epoch 18/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.6107 - val_accuracy: 0.8284 - val_loss: 0.6532\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7573 - loss: 0.7586 - val_accuracy: 0.8571 - val_loss: 0.5847\n",
            "Epoch 2/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8319 - loss: 0.5766 - val_accuracy: 0.8571 - val_loss: 0.5984\n",
            "Epoch 3/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.5696 - val_accuracy: 0.8571 - val_loss: 0.5893\n",
            "Epoch 4/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.5718 - val_accuracy: 0.8571 - val_loss: 0.6111\n",
            "Epoch 5/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.5644 - val_accuracy: 0.8571 - val_loss: 0.6104\n",
            "Epoch 6/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.5537 - val_accuracy: 0.8571 - val_loss: 0.5953\n",
            "Epoch 7/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.5558 - val_accuracy: 0.8571 - val_loss: 0.5921\n",
            "Epoch 8/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.5500 - val_accuracy: 0.8571 - val_loss: 0.5906\n",
            "Epoch 9/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.5535 - val_accuracy: 0.8571 - val_loss: 0.6145\n",
            "Epoch 10/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8341 - loss: 0.5435 - val_accuracy: 0.8571 - val_loss: 0.6084\n",
            "Epoch 11/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8315 - loss: 0.5366 - val_accuracy: 0.8571 - val_loss: 0.6094\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7679 - loss: 0.7376 - val_accuracy: 0.7845 - val_loss: 0.7892\n",
            "Epoch 2/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 0.6295 - val_accuracy: 0.7845 - val_loss: 0.8080\n",
            "Epoch 3/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.6195 - val_accuracy: 0.7845 - val_loss: 0.7966\n",
            "Epoch 4/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.6170 - val_accuracy: 0.7845 - val_loss: 0.7980\n",
            "Epoch 5/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.6202 - val_accuracy: 0.7845 - val_loss: 0.8030\n",
            "Epoch 6/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.6101 - val_accuracy: 0.7803 - val_loss: 0.7896\n",
            "Epoch 7/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.6148 - val_accuracy: 0.7845 - val_loss: 0.7953\n",
            "Epoch 8/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.6057 - val_accuracy: 0.7824 - val_loss: 0.8173\n",
            "Epoch 9/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.6038 - val_accuracy: 0.7845 - val_loss: 0.8102\n",
            "Epoch 10/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.6044 - val_accuracy: 0.7845 - val_loss: 0.8024\n",
            "Epoch 11/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.6137 - val_accuracy: 0.7845 - val_loss: 0.7979\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Average AUC: 0.6456664800643921\n",
            "Average Kappa: 0.010258136892259361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Long Short Term Memory (LSTM) Neural Network\n",
        "\n",
        "The code cell below formats the data for a recurrent model (such as a LSTM Neural Network). Remember that the data needs to be represented in 3 dimensions as opposed to 2 (note the difference in data shape as compared to above). In this cell, padding is also applied to the data and a mask is generated so that the model ignores any padded values (this is for model training efficiency).\n",
        "\n",
        "The second code cell applies a 5-fold cross-validation on a LSTM Neural Network following the structure suggested by Botelho et al. (2017).\n",
        "\n",
        "[Botelho, A. F., Baker, R. S., & Heffernan, N. T. (2017, June). Improving Sensor-Free Affect Detection Using Deep Learning. *In Proceedings of the 2017 International Conference on Artificial Intelligence in Education*, 40-51. Springer, Cham.](https://link.springer.com/chapter/10.1007/978-3-319-61425-0_4)\n",
        "\n",
        "\n",
        "**Please follow the instructions in the ASSISTments assignment for modifying and running the cross-validation code cell.**"
      ],
      "metadata": {
        "id": "fOurTYBSJ01k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_lengths = []\n",
        "X_recurrent = []\n",
        "y_recurrent = []\n",
        "mask_recurrent = []\n",
        "fold_recurrent = []\n",
        "\n",
        "def parse_data(df):\n",
        "    if (df[TARGET_FEATURES].sum(axis=1) == 1).sum() > 0:\n",
        "        keepers = df[EXPERT_FEATURES[0]].notna()\n",
        "        df = df[keepers]\n",
        "        sequence_lengths.append(len(df))\n",
        "        X_recurrent.append(df[EXPERT_FEATURES].values.reshape(-1, len(EXPERT_FEATURES)))\n",
        "        y_recurrent.append(df[TARGET_FEATURES].values.reshape(-1, len(TARGET_FEATURES)))\n",
        "        mask_recurrent.append(df[TARGET_FEATURES].sum(axis=1).values.reshape(-1, 1))\n",
        "        fold_recurrent.append(df['fold'].iloc[0])\n",
        "\n",
        "def pad_data(a, max_length):\n",
        "    pad = np.zeros((max_length - a.shape[0], a.shape[1]))\n",
        "    return np.concatenate([a, pad])\n",
        "\n",
        "# Use original_data instead of data\n",
        "original_data = original_data.sort_values(['user_id', 'clip_sequence', 'row_id']).reset_index()\n",
        "original_data.groupby(['user_id', 'clip_sequence']).apply(parse_data)\n",
        "\n",
        "max_length = max(sequence_lengths)\n",
        "X_recurrent_padded = np.stack([pad_data(i, max_length) for i in X_recurrent])\n",
        "y_recurrent_padded = np.stack([pad_data(i, max_length) for i in y_recurrent])\n",
        "mask_recurrent_padded = np.equal(np.stack([pad_data(i, max_length) for i in mask_recurrent]), 1)\n",
        "fold_recurrent = np.array(fold_recurrent)\n",
        "\n",
        "print(X_recurrent_padded.shape)\n",
        "print(y_recurrent_padded.shape)"
      ],
      "metadata": {
        "id": "vgo4IN8w4EOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19648b1-da1d-4317-b296-cacce1e85255"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-af611547b237>:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  original_data.groupby(['user_id', 'clip_sequence']).apply(parse_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(472, 432, 92)\n",
            "(472, 432, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
        "\n",
        "# Set a seed value\n",
        "seed_value= 42\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "auc_scores = []\n",
        "kappa_scores = []\n",
        "\n",
        "for fold in np.unique(fold_recurrent):\n",
        "    training = np.argwhere(fold_recurrent != fold).ravel()\n",
        "    testing = np.argwhere(fold_recurrent == fold).ravel()\n",
        "\n",
        "    X_train, X_test = X_recurrent_padded[training], X_recurrent_padded[testing]\n",
        "    y_train, y_test = y_recurrent_padded[training], y_recurrent_padded[testing]\n",
        "\n",
        "    # Flatten the sequences for simpler processing\n",
        "    # Take the last valid timestep for each sequence\n",
        "    def get_last_valid_timestep(X, y, mask):\n",
        "        X_out = []\n",
        "        y_out = []\n",
        "        for i in range(len(X)):\n",
        "            # Find last non-zero timestep\n",
        "            valid_steps = np.any(X[i] != 0, axis=1)\n",
        "            if np.any(valid_steps):\n",
        "                last_valid_idx = np.where(valid_steps)[0][-1]\n",
        "                X_out.append(X[i, last_valid_idx, :])\n",
        "                y_out.append(y[i, last_valid_idx, :])\n",
        "        return np.array(X_out), np.array(y_out)\n",
        "\n",
        "    X_train_simple, y_train_simple = get_last_valid_timestep(X_train, y_train, None)\n",
        "    X_test_simple, y_test_simple = get_last_valid_timestep(X_test, y_test, None)\n",
        "\n",
        "    # Only keep samples with valid labels (sum = 1)\n",
        "    train_valid = y_train_simple.sum(axis=1) == 1\n",
        "    test_valid = y_test_simple.sum(axis=1) == 1\n",
        "\n",
        "    if np.sum(train_valid) == 0 or np.sum(test_valid) == 0:\n",
        "        print(f\"Fold {fold}: No valid samples, skipping\")\n",
        "        continue\n",
        "\n",
        "    X_train_final = X_train_simple[train_valid]\n",
        "    y_train_final = y_train_simple[train_valid]\n",
        "    X_test_final = X_test_simple[test_valid]\n",
        "    y_test_final = y_test_simple[test_valid]\n",
        "\n",
        "    print(f\"Fold {fold}: Train samples: {len(X_train_final)}, Test samples: {len(X_test_final)}\")\n",
        "\n",
        "    # Define a simple feed-forward model\n",
        "    keras.backend.clear_session()\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(92,)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_final, y_train_final,\n",
        "                        epochs=100,\n",
        "                        validation_split=0.2,\n",
        "                        verbose=1,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test_final)\n",
        "\n",
        "    # AUC\n",
        "    auc_score = auc(y_test_final, y_pred)\n",
        "\n",
        "    # Kappa Score\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test_final, axis=1)\n",
        "    kappa_score = cohen_kappa_score(y_true_classes, y_pred_classes)\n",
        "\n",
        "    auc_scores.append(auc_score)\n",
        "    kappa_scores.append(kappa_score)\n",
        "\n",
        "    print(f\"Fold {fold}: AUC = {auc_score:.4f}, Kappa = {kappa_score:.4f}\")\n",
        "\n",
        "# Calculate the average AUC and Kappa scores across all folds\n",
        "print(f\"\\nAverage Test Set AUC: {np.mean(auc_scores):.4f}\")\n",
        "print(f\"Average Test Set Kappa: {np.mean(kappa_scores):.4f}\")"
      ],
      "metadata": {
        "id": "aHQNyz2tHkq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03587200-ed72-4984-f274-2becb87948bf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: Train samples: 31, Test samples: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2500 - loss: 126.3800 - val_accuracy: 0.1429 - val_loss: 73.8450\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.4167 - loss: 61.7966 - val_accuracy: 0.0000e+00 - val_loss: 57.5561\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.3333 - loss: 84.4571 - val_accuracy: 0.0000e+00 - val_loss: 42.6023\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.2500 - loss: 90.6415 - val_accuracy: 0.0000e+00 - val_loss: 31.8779\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.4167 - loss: 84.8375 - val_accuracy: 0.2857 - val_loss: 21.8983\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.4167 - loss: 44.7775 - val_accuracy: 0.2857 - val_loss: 17.0381\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.2917 - loss: 56.3357 - val_accuracy: 0.2857 - val_loss: 12.8404\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.3750 - loss: 74.1946 - val_accuracy: 0.4286 - val_loss: 13.7067\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5000 - loss: 51.1053 - val_accuracy: 0.4286 - val_loss: 16.8235\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6250 - loss: 35.9294 - val_accuracy: 0.4286 - val_loss: 19.7143\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.4167 - loss: 58.2821 - val_accuracy: 0.4286 - val_loss: 22.4859\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5417 - loss: 41.8629 - val_accuracy: 0.5714 - val_loss: 24.8349\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5000 - loss: 37.7622 - val_accuracy: 0.5714 - val_loss: 26.6014\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5417 - loss: 32.5839 - val_accuracy: 0.5714 - val_loss: 27.7402\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3750 - loss: 70.8944 - val_accuracy: 0.5714 - val_loss: 28.6367\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6250 - loss: 51.3757 - val_accuracy: 0.5714 - val_loss: 29.0853\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.5833 - loss: 58.7580 - val_accuracy: 0.5714 - val_loss: 29.4539\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Fold 0: AUC = 0.3248, Kappa = 0.1316\n",
            "Fold 1: Train samples: 34, Test samples: 8\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2963 - loss: 94.9751 - val_accuracy: 0.2857 - val_loss: 12.8160\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1852 - loss: 74.4454 - val_accuracy: 0.7143 - val_loss: 11.0116\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.4444 - loss: 31.2644 - val_accuracy: 0.7143 - val_loss: 14.1882\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.3333 - loss: 68.7222 - val_accuracy: 0.7143 - val_loss: 17.4080\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.4815 - loss: 38.3631 - val_accuracy: 0.7143 - val_loss: 20.2134\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.3333 - loss: 55.7280 - val_accuracy: 0.7143 - val_loss: 22.5751\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5185 - loss: 49.3299 - val_accuracy: 0.7143 - val_loss: 23.8859\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4074 - loss: 35.8541 - val_accuracy: 0.7143 - val_loss: 24.5982\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.4074 - loss: 37.7605 - val_accuracy: 0.7143 - val_loss: 24.9852\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7407 - loss: 11.9483 - val_accuracy: 0.5714 - val_loss: 25.3566\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4074 - loss: 31.4468 - val_accuracy: 0.5714 - val_loss: 26.8303\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5556 - loss: 18.2727 - val_accuracy: 0.5714 - val_loss: 28.0458\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Fold 1: AUC = 0.6111, Kappa = 0.0000\n",
            "Fold 2: Train samples: 35, Test samples: 7\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1429 - loss: 154.3983 - val_accuracy: 0.0000e+00 - val_loss: 86.6425\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.2143 - loss: 91.0803 - val_accuracy: 0.0000e+00 - val_loss: 72.6397\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1071 - loss: 117.4878 - val_accuracy: 0.0000e+00 - val_loss: 57.6805\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2143 - loss: 87.0302 - val_accuracy: 0.0000e+00 - val_loss: 41.2938\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.3214 - loss: 89.7988 - val_accuracy: 0.2857 - val_loss: 27.7768\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.3214 - loss: 86.1871 - val_accuracy: 0.7143 - val_loss: 22.1265\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.2143 - loss: 79.0183 - val_accuracy: 0.7143 - val_loss: 19.4822\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2143 - loss: 81.4651 - val_accuracy: 0.7143 - val_loss: 18.8784\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.4643 - loss: 35.5808 - val_accuracy: 0.7143 - val_loss: 19.3028\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.3214 - loss: 54.7250 - val_accuracy: 0.7143 - val_loss: 19.7983\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5357 - loss: 40.1065 - val_accuracy: 0.7143 - val_loss: 20.2512\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5714 - loss: 31.7562 - val_accuracy: 0.7143 - val_loss: 20.3416\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5357 - loss: 39.7774 - val_accuracy: 0.7143 - val_loss: 20.4622\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5000 - loss: 48.9680 - val_accuracy: 0.7143 - val_loss: 20.7259\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.5357 - loss: 56.5123 - val_accuracy: 0.7143 - val_loss: 20.8227\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5000 - loss: 56.3739 - val_accuracy: 0.7143 - val_loss: 20.7967\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5714 - loss: 26.8855 - val_accuracy: 0.7143 - val_loss: 21.0913\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.4643 - loss: 39.7687 - val_accuracy: 0.7143 - val_loss: 21.4373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 18 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dbc3263c4a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Fold 2: AUC = 0.6042, Kappa = -0.1667\n",
            "Fold 3: Train samples: 34, Test samples: 8\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1852 - loss: 231.9701 - val_accuracy: 0.0000e+00 - val_loss: 48.6841\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.2222 - loss: 164.4011 - val_accuracy: 0.1429 - val_loss: 24.3854\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.1852 - loss: 126.7923 - val_accuracy: 0.5714 - val_loss: 3.8276\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2222 - loss: 103.1264 - val_accuracy: 0.8571 - val_loss: 2.0164\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.4074 - loss: 52.6965 - val_accuracy: 0.7143 - val_loss: 3.3190\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.3704 - loss: 57.2468 - val_accuracy: 0.7143 - val_loss: 4.5247\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.4815 - loss: 49.6286 - val_accuracy: 0.7143 - val_loss: 5.6791\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5556 - loss: 80.6150 - val_accuracy: 0.7143 - val_loss: 6.7782\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.3333 - loss: 71.1217 - val_accuracy: 0.7143 - val_loss: 7.6374\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5185 - loss: 44.5570 - val_accuracy: 0.7143 - val_loss: 8.3685\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.4444 - loss: 59.2998 - val_accuracy: 0.7143 - val_loss: 8.8825\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.3333 - loss: 41.5503 - val_accuracy: 0.7143 - val_loss: 9.2356\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.4815 - loss: 75.9378 - val_accuracy: 0.7143 - val_loss: 9.4802\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.4815 - loss: 35.7187 - val_accuracy: 0.7143 - val_loss: 9.5322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 19 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dbc2941cc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "Fold 3: AUC = 0.4188, Kappa = 0.0000\n",
            "Fold 4: Train samples: 34, Test samples: 8\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1481 - loss: 144.3200 - val_accuracy: 0.0000e+00 - val_loss: 91.1467\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.0741 - loss: 105.9552 - val_accuracy: 0.0000e+00 - val_loss: 75.9231\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.1852 - loss: 113.7309 - val_accuracy: 0.0000e+00 - val_loss: 59.5858\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.3704 - loss: 52.9074 - val_accuracy: 0.0000e+00 - val_loss: 45.5124\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.2222 - loss: 72.0640 - val_accuracy: 0.1429 - val_loss: 37.8763\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2593 - loss: 45.4384 - val_accuracy: 0.4286 - val_loss: 40.9441\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.3333 - loss: 52.9485 - val_accuracy: 0.5714 - val_loss: 46.7584\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4815 - loss: 56.2747 - val_accuracy: 0.5714 - val_loss: 50.9595\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4444 - loss: 40.1625 - val_accuracy: 0.5714 - val_loss: 54.3289\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.5556 - loss: 33.2919 - val_accuracy: 0.5714 - val_loss: 55.3527\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.3333 - loss: 39.3633 - val_accuracy: 0.5714 - val_loss: 55.5281\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5185 - loss: 27.1599 - val_accuracy: 0.5714 - val_loss: 54.4255\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.4444 - loss: 22.6773 - val_accuracy: 0.5714 - val_loss: 52.9049\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5556 - loss: 26.4170 - val_accuracy: 0.5714 - val_loss: 50.7564\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5185 - loss: 37.1000 - val_accuracy: 0.5714 - val_loss: 49.1637\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "Fold 4: AUC = 0.6444, Kappa = 0.0303\n",
            "\n",
            "Average Test Set AUC: 0.5207\n",
            "Average Test Set Kappa: -0.0010\n"
          ]
        }
      ]
    }
  ]
}